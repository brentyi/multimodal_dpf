{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import time\n",
    "\n",
    "from lib import dpf\n",
    "from lib import localization_models\n",
    "\n",
    "def to_torch(x):\n",
    "    return torch.from_numpy(x.astype(np.float32)).to(device)\n",
    "def to_numpy(x):\n",
    "    return x.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Some helpers for generating data\n",
    "###\n",
    "\n",
    "observer = localization_models.BeaconObserver()\n",
    "observer.add_beacon((5, 3), 0.2)\n",
    "observer.add_beacon((22, 8), 0.5)\n",
    "observer.add_beacon((12, -10), 0.5)\n",
    "\n",
    "# Simulation\n",
    "def simulate_trajectory(timesteps=100):\n",
    "    dynamics = localization_models.RobotDynamicsModel()\n",
    "\n",
    "    # Generate states, control inputs\n",
    "    states = [np.array([0., 0., 0.])]\n",
    "    \n",
    "    # First control input is unuseful -- inject NaNs to make sure they're never used :)\n",
    "    controls = [np.array([np.nan, np.nan])]\n",
    "    for _ in range(timesteps):\n",
    "        control = torch.from_numpy(np.random.uniform(\n",
    "            low=[0, -0.1], high=[0.4, 0.1], size=(2,)).astype(np.float32))\n",
    "        new_state = dynamics.forward(\n",
    "            torch.from_numpy(states[-1][np.newaxis, np.newaxis, :].astype(np.float32)), control[np.newaxis,:], noisy=True)\n",
    "\n",
    "        states.append(new_state[0,0].numpy())\n",
    "        controls.append(control.numpy())\n",
    "\n",
    "    # Remove initial state\n",
    "    states = states\n",
    "\n",
    "    # Generate observations from ground-truth states\n",
    "    observations = observer.forward(states)\n",
    "\n",
    "    return states, observations, controls\n",
    "\n",
    "# Dead-reckoning\n",
    "def dead_reckon(controls, initial_state=np.array([0., 0., 0.])):\n",
    "    dynamics = localization_models.RobotDynamicsModel()\n",
    "\n",
    "    states = [initial_state]\n",
    "    for control in controls:\n",
    "        new_state = dynamics.forward(\n",
    "            torch.from_numpy(states[-1][np.newaxis, :].astype(np.float32)), control, noisy=False)\n",
    "        states.append(new_state[0].numpy())\n",
    "    \n",
    "    # Remove initial state and return\n",
    "    return states\n",
    "\n",
    "# Visualization helper\n",
    "def plot_trajectories(*states_list, **states_dict):\n",
    "    import itertools\n",
    "    plt.figure()\n",
    "    for label, states in itertools.chain(states_dict.items(), enumerate(states_list)):\n",
    "        if label == \"particles\":\n",
    "            # Format for particles should be states, log_weights\n",
    "            assert len(states) == 2\n",
    "            states, log_weights = states\n",
    "            weights = np.exp(log_weights)\n",
    "            weights /= np.max(weights)\n",
    "            \n",
    "            rgba = np.zeros((len(weights),4))\n",
    "            rgba[:,3] = weights * 0.9 + 0.1\n",
    "\n",
    "            x = np.asarray(states).T[0]\n",
    "            y = np.asarray(states).T[1]\n",
    "            plt.scatter(x, y, label=label, c=rgba)\n",
    "        else:\n",
    "            x = np.asarray(states).T[0]\n",
    "            y = np.asarray(states).T[1]\n",
    "            plt.scatter(x, y, label=label)\n",
    "\n",
    "        \n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generate some training data\n",
    "#\n",
    "training_trajectories = []\n",
    "for _ in range(100):\n",
    "    # States, observations, controls\n",
    "    s, o, u = simulate_trajectory(80)\n",
    "    training_trajectories.append((np.asarray(s), np.asarray(o), np.asarray(u)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_trajectories(*[t[0] for t in training_trajectories[:5]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize particle filter network\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "try:\n",
    "    del pfnet\n",
    "    torch.cuda.empty_cache()\n",
    "    print(\"Deleted old model!\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "dynamics = localization_models.DeepRobotDynamicsModel()\n",
    "measurements = localization_models.DeepBeaconMeasurementModel()\n",
    "# measurements = localization_models.BeaconMeasurementModel(observer)\n",
    "pfnet = dpf.ParticleFilterNetwork(dynamics, measurements, 1.0).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = dpf.ParticleFilterDataset(\n",
    "    training_trajectories[0:1],\n",
    "    subsequence_length=2,\n",
    "    particle_count=100,\n",
    "    particle_variances = [3, 3, 0.3]\n",
    ")\n",
    "trainset_loader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define optimizer\n",
    "optimizer = optim.Adam(pfnet.parameters())\n",
    "def train(learning_rate=1e-5, log=True):\n",
    "    # Set learning rate\n",
    "    # print(\"Setting learning rate to\", learning_rate)\n",
    "    for g in optimizer.param_groups:\n",
    "        g['lr'] = learning_rate\n",
    "\n",
    "    # Train for 1 epoch\n",
    "    for batch_idx, batch in enumerate(trainset_loader):\n",
    "        # Transfer to GPU and pull out batch data\n",
    "        batch_gpu = [x.to(device) for x in batch]\n",
    "        batch_particles, batch_states, batch_obs, batch_controls = batch_gpu\n",
    "\n",
    "        # N = batch size, M = particle count\n",
    "        N, timesteps, obs_dim = batch_obs.shape\n",
    "        N, timesteps, control_dim = batch_controls.shape\n",
    "        N, timesteps, state_dim = batch_states.shape\n",
    "        N, M, state_dim = batch_particles.shape\n",
    "        assert batch_obs.shape == (N, timesteps, obs_dim)\n",
    "        assert batch_controls.shape == (N, timesteps, control_dim)\n",
    "\n",
    "        # Give all particle equal weights\n",
    "        particles = batch_particles\n",
    "        log_weights = torch.ones((N, M), device=device) * (-np.log(M))\n",
    "\n",
    "        for t in range(1, timesteps):\n",
    "            prev_particles = particles\n",
    "            prev_log_weights = log_weights\n",
    "\n",
    "            _, new_particles, new_log_weights = pfnet.forward(\n",
    "                prev_particles,\n",
    "                prev_log_weights,\n",
    "                batch_obs[:,t - 1,:],\n",
    "                batch_controls[:,t,:],\n",
    "                resample=False\n",
    "            )\n",
    "            \n",
    "            loss = dpf.gmm_loss(\n",
    "                particles_states=new_particles,\n",
    "                log_weights=new_log_weights,\n",
    "                true_states=batch_states[:, t, :],\n",
    "                gmm_variances=np.array([0.2, 0.2, 0.1])\n",
    "            )\n",
    "\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward(retain_graph=False)\n",
    "            optimizer.step()\n",
    "            assert loss.shape == ()\n",
    "\n",
    "            particles = new_particles.detach()\n",
    "            log_weights = new_log_weights.detach()\n",
    "\n",
    "    if log:\n",
    "        max_belief = torch.max(torch.exp(new_log_weights))\n",
    "        print(to_numpy(loss), \"\\t\", to_numpy(new_log_weights))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1000):\n",
    "    train(1e-3, log=(i%10 == 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "particle_states = torch.from_numpy(\n",
    "    np.random.normal(0., 1., size=(1, 20, 3))\n",
    ").float().to(device)\n",
    "observations = torch.from_numpy(observer.forward(particle_states[0:1, 0].cpu().numpy())).float().to(device)\n",
    "measurements(observations, particle_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "traj_index = 0\n",
    "true_states, observations, controls = training_trajectories[traj_index]\n",
    "num_particles = 100\n",
    "\n",
    "start = 0\n",
    "end = start + 5\n",
    "\n",
    "particle_states = torch.FloatTensor(\n",
    "    [[true_states[start] for _ in range(num_particles)]]).to(device)\n",
    "\n",
    "# particle_variances = [4, 4, 0.1]\n",
    "# n = torch.distributions.Normal(torch.tensor([0.]), torch.tensor(particle_variances))\n",
    "# particle_states += n.sample((num_particles, )).to(device)\n",
    "particle_weights = torch.ones((1,num_particles)).to(device)\n",
    "\n",
    "states = []\n",
    "for control, observation in zip(controls[start + 1:end + 1], observations[start:end]):\n",
    "    # Type conversions\n",
    "    observation = to_torch(observation[np.newaxis,:])\n",
    "    control = to_torch(control[np.newaxis,:])\n",
    "\n",
    "    # Particle filter network: forward\n",
    "    best_state, particle_states, particle_weights = pfnet.forward(\n",
    "        particle_states, particle_weights, observation, control, resample=False)\n",
    "    # print (np.std(particle_weights.cpu().detach().numpy()), np.mean(particle_weights.cpu().detach().numpy()))\n",
    "\n",
    "    states.append(to_numpy(best_state))\n",
    "#     print(best_state)\n",
    "pf_states = np.array(states)\n",
    "particle_states = particle_states[0].cpu().detach().numpy()\n",
    "particle_weights = particle_weights[0].cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Trained network\")\n",
    "# print(np.exp(particle_weights))\n",
    "plot_trajectories(\n",
    "    true=true_states,\n",
    "    pf=pf_states,\n",
    "    particles=(particle_states, particle_weights),\n",
    "    beacons=observer.locations\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Trained network\")\n",
    "plot_trajectories(\n",
    "    true=true_states,\n",
    "    pf=pf_states,\n",
    "    particles=(particle_states[0].cpu().numpy(), particle_weights[0].cpu().numpy()),\n",
    "    beacons=observer.locations\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
